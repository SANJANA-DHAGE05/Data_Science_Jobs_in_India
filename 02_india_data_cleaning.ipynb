{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55526ea2-50d7-41be-8f6f-fb63f2870c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ef4309-1fbb-4bf8-972a-4547db2fe65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: 1602 rows\n",
      "\n",
      "‚úì Dropped index column\n",
      "‚úì Company names cleaned\n",
      "\n",
      "‚úì Job categories created:\n",
      "job_category\n",
      "Data Analyst       749\n",
      "Data Engineer      430\n",
      "Data Scientist     373\n",
      "Other Data Role     50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úì Seniority levels:\n",
      "seniority\n",
      "Mid-Level    860\n",
      "Senior       742\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úì Salary data cleaned!\n",
      "Jobs with salary data: 1602 (100.0%)\n",
      "\n",
      "‚úì Experience data cleaned!\n",
      "Experience range: 0 to 21 years\n",
      "\n",
      "‚úì Skills extracted from job titles!\n",
      "\n",
      "Before removing duplicates: 1602 rows\n",
      "After removing duplicates: 1602 rows\n",
      "\n",
      "‚úì Outliers removed (salaries < 1 LPA or > 100 LPA)\n",
      "\n",
      "============================================================\n",
      "DATA CLEANING COMPLETE! ‚úÖ\n",
      "============================================================\n",
      "\n",
      "Final dataset: 1602 rows, 32 columns\n",
      "\n",
      "üìä JOB CATEGORY DISTRIBUTION:\n",
      "job_category\n",
      "Data Analyst       749\n",
      "Data Engineer      430\n",
      "Data Scientist     373\n",
      "Other Data Role     50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä SENIORITY DISTRIBUTION:\n",
      "seniority\n",
      "Mid-Level    860\n",
      "Senior       742\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üí∞ SALARY STATISTICS:\n",
      "Median Salary: ‚Çπ11.9 LPA\n",
      "Mean Salary: ‚Çπ13.2 LPA\n",
      "Min: ‚Çπ1.4 LPA\n",
      "Max: ‚Çπ82.0 LPA\n",
      "Jobs with salary data: 1602\n",
      "\n",
      "üè¢ TOP 10 COMPANIES:\n",
      "company\n",
      "IBM                 10\n",
      "Accenture           10\n",
      "Mindtree            10\n",
      "DXC Technology      10\n",
      "JP Morgan Chase     10\n",
      "UST                 10\n",
      "HCL Technologies    10\n",
      "Cognizant           10\n",
      "Capgemini           10\n",
      "Infosys             10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üõ†Ô∏è TOP SKILLS FOUND:\n",
      "  Machine Learning    :   59 jobs (3.7%)\n",
      "\n",
      "‚úì Cleaned data saved to: data/processed/india_jobs_cleaned.csv\n",
      "\n",
      "üöÄ READY FOR ANALYSIS AND DASHBOARD!\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/raw/Data_Science_Jobs_in_India.csv')\n",
    "print(f\"Original data: {len(df)} rows\\n\")\n",
    "\n",
    "# ===== DROP UNNECESSARY COLUMN =====\n",
    "if 'Unnamed: 0' in df.columns or df.columns[0] == '':\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    print(\"‚úì Dropped index column\")\n",
    "\n",
    "# ===== CLEAN COMPANY NAMES =====\n",
    "df['company_name'] = df['company_name'].str.strip()\n",
    "print(\"‚úì Company names cleaned\")\n",
    "\n",
    "# ===== CATEGORIZE JOB ROLES =====\n",
    "def categorize_job_role(title):\n",
    "    \"\"\"Categorize jobs into specific roles\"\"\"\n",
    "    if pd.isna(title):\n",
    "        return 'Other'\n",
    "    \n",
    "    title_lower = str(title).lower()\n",
    "    \n",
    "    # Data Science roles\n",
    "    if any(word in title_lower for word in ['data scientist', 'ds ', 'scientist']):\n",
    "        return 'Data Scientist'\n",
    "    \n",
    "    # Data Analyst roles\n",
    "    elif any(word in title_lower for word in ['data analyst', 'business analyst', 'analyst', 'analytics']):\n",
    "        return 'Data Analyst'\n",
    "    \n",
    "    # Data Engineer roles\n",
    "    elif any(word in title_lower for word in ['data engineer', 'etl', 'big data', 'engineer']):\n",
    "        return 'Data Engineer'\n",
    "    \n",
    "    # ML Engineer roles\n",
    "    elif any(word in title_lower for word in ['machine learning', 'ml engineer', 'ai engineer', 'mlops']):\n",
    "        return 'ML Engineer'\n",
    "    \n",
    "    # BI roles\n",
    "    elif any(word in title_lower for word in ['business intelligence', 'bi ', 'power bi', 'tableau']):\n",
    "        return 'BI Developer'\n",
    "    \n",
    "    # Research roles\n",
    "    elif any(word in title_lower for word in ['research', 'researcher']):\n",
    "        return 'Research Scientist'\n",
    "    \n",
    "    # Manager roles\n",
    "    elif any(word in title_lower for word in ['manager', 'lead', 'head', 'director']):\n",
    "        return 'Manager/Lead'\n",
    "    \n",
    "    # Consultant roles\n",
    "    elif any(word in title_lower for word in ['consultant', 'advisor']):\n",
    "        return 'Consultant'\n",
    "    \n",
    "    else:\n",
    "        return 'Other Data Role'\n",
    "\n",
    "df['job_category'] = df['job_title'].apply(categorize_job_role)\n",
    "\n",
    "print(\"\\n‚úì Job categories created:\")\n",
    "print(df['job_category'].value_counts())\n",
    "\n",
    "# ===== EXTRACT SENIORITY LEVEL =====\n",
    "def extract_seniority(title):\n",
    "    \"\"\"Extract seniority level from job title\"\"\"\n",
    "    if pd.isna(title):\n",
    "        return 'Mid-Level'\n",
    "    \n",
    "    title_lower = str(title).lower()\n",
    "    \n",
    "    # Senior level\n",
    "    if any(word in title_lower for word in ['senior', 'sr.', 'sr ', 'lead', 'principal', 'chief', 'head', 'director', 'manager']):\n",
    "        return 'Senior'\n",
    "    \n",
    "    # Junior level\n",
    "    elif any(word in title_lower for word in ['junior', 'jr.', 'jr ', 'intern', 'trainee', 'fresher', 'associate', 'entry']):\n",
    "        return 'Junior'\n",
    "    \n",
    "    # Mid level (default)\n",
    "    else:\n",
    "        return 'Mid-Level'\n",
    "\n",
    "df['seniority'] = df['job_title'].apply(extract_seniority)\n",
    "\n",
    "print(\"\\n‚úì Seniority levels:\")\n",
    "print(df['seniority'].value_counts())\n",
    "\n",
    "# ===== CLEAN SALARY DATA =====\n",
    "def parse_salary_india(salary_str):\n",
    "    \"\"\"Parse Indian salary format (LPA/CTC)\"\"\"\n",
    "    if pd.isna(salary_str):\n",
    "        return np.nan\n",
    "    \n",
    "    # Convert to string and clean\n",
    "    salary_str = str(salary_str).lower().strip()\n",
    "    \n",
    "    # Remove common words\n",
    "    salary_str = salary_str.replace('lpa', '').replace('ctc', '').replace('‚Çπ', '').replace('rs', '').replace(',', '').strip()\n",
    "    \n",
    "    # If it's already a number\n",
    "    try:\n",
    "        return float(salary_str)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Extract first number found\n",
    "    numbers = re.findall(r'\\d+\\.?\\d*', salary_str)\n",
    "    if numbers:\n",
    "        return float(numbers[0])\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "# Apply to all salary columns\n",
    "df['avg_salary_lpa'] = df['avg_salary'].apply(parse_salary_india)\n",
    "df['min_salary_lpa'] = df['min_salary'].apply(parse_salary_india)\n",
    "df['max_salary_lpa'] = df['max_salary'].apply(parse_salary_india)\n",
    "\n",
    "print(\"\\n‚úì Salary data cleaned!\")\n",
    "print(f\"Jobs with salary data: {df['avg_salary_lpa'].notna().sum()} ({df['avg_salary_lpa'].notna().sum()/len(df)*100:.1f}%)\")\n",
    "\n",
    "# ===== CLEAN EXPERIENCE DATA =====\n",
    "# min_experience is already numeric, just clean it\n",
    "df['experience_years'] = df['min_experience'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"\\n‚úì Experience data cleaned!\")\n",
    "print(f\"Experience range: {df['experience_years'].min()} to {df['experience_years'].max()} years\")\n",
    "\n",
    "# ===== EXTRACT SKILLS FROM JOB TITLES =====\n",
    "# Define key skills to search for in job titles\n",
    "skills_dict = {\n",
    "    'python': ['python', 'py'],\n",
    "    'r': [' r ', ' r,', 'r programming'],\n",
    "    'sql': ['sql', 'mysql', 'postgresql'],\n",
    "    'excel': ['excel', 'spreadsheet'],\n",
    "    'tableau': ['tableau'],\n",
    "    'power_bi': ['power bi', 'powerbi', 'power-bi'],\n",
    "    'machine_learning': ['machine learning', 'ml', 'deep learning'],\n",
    "    'statistics': ['statistics', 'statistical'],\n",
    "    'spark': ['spark', 'pyspark'],\n",
    "    'hadoop': ['hadoop'],\n",
    "    'aws': ['aws', 'amazon web services'],\n",
    "    'azure': ['azure'],\n",
    "    'tensorflow': ['tensorflow', 'tf'],\n",
    "    'pytorch': ['pytorch'],\n",
    "    'nlp': ['nlp', 'natural language'],\n",
    "    'computer_vision': ['computer vision', 'cv', 'image processing'],\n",
    "    'big_data': ['big data', 'bigdata'],\n",
    "    'etl': ['etl', 'pipeline'],\n",
    "    'git': ['git', 'github'],\n",
    "    'docker': ['docker', 'container'],\n",
    "    'data_visualization': ['visualization', 'viz', 'dashboard']\n",
    "}\n",
    "\n",
    "# Search in job titles\n",
    "df['job_title_lower'] = df['job_title'].fillna('').str.lower()\n",
    "\n",
    "for skill, keywords in skills_dict.items():\n",
    "    df[f'skill_{skill}'] = df['job_title_lower'].apply(\n",
    "        lambda x: 1 if any(keyword in str(x) for keyword in keywords) else 0\n",
    "    )\n",
    "\n",
    "df = df.drop('job_title_lower', axis=1)\n",
    "print(\"\\n‚úì Skills extracted from job titles!\")\n",
    "\n",
    "# ===== ADD COUNTRY =====\n",
    "df['country'] = 'India'\n",
    "\n",
    "# ===== REMOVE DUPLICATES =====\n",
    "print(f\"\\nBefore removing duplicates: {len(df)} rows\")\n",
    "df = df.drop_duplicates(subset=['company_name', 'job_title', 'min_experience'], keep='first')\n",
    "print(f\"After removing duplicates: {len(df)} rows\")\n",
    "\n",
    "# ===== HANDLE OUTLIERS IN SALARY =====\n",
    "# Remove unrealistic salaries (< 1 LPA or > 100 LPA)\n",
    "df.loc[df['avg_salary_lpa'] < 1, 'avg_salary_lpa'] = np.nan\n",
    "df.loc[df['avg_salary_lpa'] > 100, 'avg_salary_lpa'] = np.nan\n",
    "df.loc[df['min_salary_lpa'] < 1, 'min_salary_lpa'] = np.nan\n",
    "df.loc[df['max_salary_lpa'] > 100, 'max_salary_lpa'] = np.nan\n",
    "\n",
    "print(\"\\n‚úì Outliers removed (salaries < 1 LPA or > 100 LPA)\")\n",
    "\n",
    "# ===== SELECT FINAL COLUMNS =====\n",
    "final_columns = [\n",
    "    'company_name', 'job_title', 'job_category', 'seniority', 'country',\n",
    "    'experience_years', 'min_experience',\n",
    "    'avg_salary_lpa', 'min_salary_lpa', 'max_salary_lpa',\n",
    "    'num_of_salaries'\n",
    "] + [col for col in df.columns if col.startswith('skill_')]\n",
    "\n",
    "df_clean = df[final_columns].copy()\n",
    "\n",
    "# Rename for consistency\n",
    "df_clean = df_clean.rename(columns={\n",
    "    'company_name': 'company',\n",
    "    'experience_years': 'min_experience_clean'\n",
    "})\n",
    "\n",
    "# ===== SAVE CLEANED DATA =====\n",
    "# Create directory if not exists\n",
    "import os\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "df_clean.to_csv('data/processed/india_jobs_cleaned.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA CLEANING COMPLETE! ‚úÖ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nFinal dataset: {len(df_clean)} rows, {len(df_clean.columns)} columns\")\n",
    "\n",
    "print(\"\\nüìä JOB CATEGORY DISTRIBUTION:\")\n",
    "print(df_clean['job_category'].value_counts())\n",
    "\n",
    "print(\"\\nüìä SENIORITY DISTRIBUTION:\")\n",
    "print(df_clean['seniority'].value_counts())\n",
    "\n",
    "print(\"\\nüí∞ SALARY STATISTICS:\")\n",
    "salary_stats = df_clean['avg_salary_lpa'].describe()\n",
    "print(f\"Median Salary: ‚Çπ{df_clean['avg_salary_lpa'].median():.1f} LPA\")\n",
    "print(f\"Mean Salary: ‚Çπ{df_clean['avg_salary_lpa'].mean():.1f} LPA\")\n",
    "print(f\"Min: ‚Çπ{df_clean['avg_salary_lpa'].min():.1f} LPA\")\n",
    "print(f\"Max: ‚Çπ{df_clean['avg_salary_lpa'].max():.1f} LPA\")\n",
    "print(f\"Jobs with salary data: {df_clean['avg_salary_lpa'].notna().sum()}\")\n",
    "\n",
    "print(\"\\nüè¢ TOP 10 COMPANIES:\")\n",
    "print(df_clean['company'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nüõ†Ô∏è TOP SKILLS FOUND:\")\n",
    "skill_cols = [col for col in df_clean.columns if col.startswith('skill_')]\n",
    "skill_counts = {}\n",
    "for col in skill_cols:\n",
    "    skill_name = col.replace('skill_', '').replace('_', ' ').title()\n",
    "    count = df_clean[col].sum()\n",
    "    if count > 0:\n",
    "        skill_counts[skill_name] = count\n",
    "\n",
    "top_skills = sorted(skill_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "for skill, count in top_skills:\n",
    "    pct = (count / len(df_clean)) * 100\n",
    "    print(f\"  {skill:20s}: {count:4d} jobs ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n‚úì Cleaned data saved to: data/processed/india_jobs_cleaned.csv\")\n",
    "print(\"\\nüöÄ READY FOR ANALYSIS AND DASHBOARD!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
